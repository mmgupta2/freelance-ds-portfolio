{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3cea51f0-b2ad-40a7-b3eb-99856cbb012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3.1\n",
    "%reset -f\n",
    "import os\n",
    "from haystack import Pipeline\n",
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchBM25Retriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.utils import Secret\n",
    "from elasticsearch import Elasticsearch, NotFoundError\n",
    "import huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32864244-3640-4841-8c5f-6ab513afbaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Elasticsearch is running!\n",
      "{'name': '2a8208dd71bc', 'cluster_name': 'docker-cluster', 'cluster_uuid': '_hkO__sjSjq07Fxmo5KzJw', 'version': {'number': '8.12.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '1665f706fd9354802c02146c1e6b5c0fbcddfbc9', 'build_date': '2024-01-11T10:05:27.953830042Z', 'build_snapshot': False, 'lucene_version': '9.9.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "#debugging\n",
    "import requests\n",
    "try:\n",
    "    res = requests.get(\"http://localhost:9200\")\n",
    "    if res.status_code == 200:\n",
    "        print(\"Elasticsearch is running!\")\n",
    "        print(res.json())\n",
    "    else:\n",
    "        print(f\"Elasticsearch responded with status code {res.status_code}\")\n",
    "except Exception as e:\n",
    "    print(\"Could not connect to Elasticsearch.\")\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c65b9-2a70-4c82-95cb-808de33cf978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    hosts=\"http://localhost:9200\",\n",
    "    index=\"transcripts\"\n",
    ")\n",
    "\n",
    "print(\"Connected to Elasticsearch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d68cb-ad02-45c2-9e8f-57d0ef6727bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transcripts extracted to: transcripts_unzipped\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"./transcripts.zip\"  \n",
    "extract_dir = \"transcripts_unzipped\"\n",
    "\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"Transcripts extracted to: {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42efa79-40df-4d12-b8a0-8f1caa160696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import Document\n",
    "\n",
    "transcript_folder = os.path.join(extract_dir, \"transcripts\")\n",
    "\n",
    "docs = []\n",
    "for filename in os.listdir(transcript_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(transcript_folder, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            docs.append(Document(content=content, meta={\"name\": filename}))\n",
    "\n",
    "# Index the docs\n",
    "document_store.write_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540e229-0eae-4b14-b278-fbe6a9c79330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3.2\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.utils import Secret\n",
    "\n",
    "generator = HuggingFaceAPIGenerator(api_type=\"serverless_inference_api\",\n",
    "                                    api_params={\"model\": \"microsoft/Phi-3.5-mini-instruct\"},\n",
    "                                    token=Secret.from_token(\"huggingface_token\"),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59fb6acf-f442-4ab8-88c0-6b375dc0c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "  <|system|>\n",
    "  You are a helpful assistant.<|end|>\n",
    "  <|user|>\n",
    "  Given the following information, answer the question.\n",
    "\n",
    "  Context: \n",
    "  {% for document in documents %}\n",
    "      {{ document.content }}\n",
    "  {% endfor %}\n",
    "\n",
    "  Question: {{ query }}?<|end|>\n",
    "  <|assistant|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5813a810-a5a0-4ccb-88cd-6ebbd49e4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = ElasticsearchBM25Retriever(document_store=document_store)\n",
    "generator = HuggingFaceAPIGenerator(\n",
    "    api_type=\"serverless_inference_api\",\n",
    "    api_params={\"model\": \"microsoft/Phi-3.5-mini-instruct\", \"max_new_tokens\": 200 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447cce2-22c4-4ccd-91d8-fff177078096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "import os\n",
    "from haystack import Pipeline\n",
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchBM25Retriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.utils import Secret\n",
    "from haystack.dataclasses import Document\n",
    "from elasticsearch import Elasticsearch, NotFoundError\n",
    "import huggingface_hub\n",
    "import zipfile\n",
    "import os\n",
    "# connect to your existing document store\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    hosts=\"http://localhost:9200\",\n",
    "    index=\"transcripts\"\n",
    ")\n",
    "\n",
    "if document_store.count_documents() == 0:\n",
    "    print(\"ðŸ“„ Index is empty. Ingesting documents...\")\n",
    "\n",
    "    zip_path = \"./transcripts.zip\"  \n",
    "    extract_dir = \"transcripts_unzipped\"\n",
    "\n",
    "    if not os.path.exists(extract_dir):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "\n",
    "    transcript_folder = os.path.join(extract_dir, \"transcripts\")\n",
    "\n",
    "    docs = []\n",
    "    for filename in os.listdir(transcript_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(transcript_folder, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                docs.append(Document(content=content, meta={\"name\": filename}))\n",
    "\n",
    "    document_store.write_documents(docs)\n",
    "    \n",
    "# retriever and generator setup\n",
    "retriever = ElasticsearchBM25Retriever(document_store=document_store)\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "<|system|>\n",
    "You are a helpful assistant.<|end|>\n",
    "<|user|>\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context: \n",
    "{% for document in documents %}\n",
    "    {{ document.content[:5000] }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ query }}?<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "generator = HuggingFaceAPIGenerator(\n",
    "    api_type=\"serverless_inference_api\",\n",
    "    api_params={\"model\": \"microsoft/Phi-3.5-mini-instruct\", \"max_new_tokens\": 200},\n",
    "    token=Secret.from_token(\"huggingface_hub_token\")  # Replace with your Hugging Face Hub token\n",
    ")\n",
    "\n",
    "# define RAG pipeline\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "rag_pipeline.add_component(\"llm\", generator)\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "with st.sidebar:\n",
    "    openai_api_key = st.text_input(\"OpenAI API Key\", key=\"chatbot_api_key\", type=\"password\")\n",
    "    \"[Get an OpenAI API key](https://platform.openai.com/account/api-keys)\"\n",
    "    \"[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)\"\n",
    "    \"[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)\"\n",
    "\n",
    "st.title(\"ðŸ’¬ Course Chatbot\")\n",
    "st.caption(\"ðŸš€ Interactive Q&A with Elasticsearch, Haystack, and HuggingFace\")\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "for msg in st.session_state.messages:\n",
    "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "if prompt := st.chat_input(\"Ask a question about the course transcripts\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "\n",
    "    \n",
    "    retrieved_docs = retriever.run(query=prompt)[\"documents\"]\n",
    "    limited_docs = retrieved_docs[:1]  # you can do [:2] or [:3] depending on length\n",
    "\n",
    "    \n",
    "    prompt_builder = PromptBuilder(template=template, required_variables=[\"documents\", \"query\"])\n",
    "    final_prompt = prompt_builder.run(documents=limited_docs, query=prompt)[\"prompt\"]\n",
    "\n",
    "    \n",
    "    response = generator.run(prompt=final_prompt)[\"replies\"][0]\n",
    "    \n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    st.chat_message(\"assistant\").markdown(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0458ee5d-304d-4deb-a0a1-ba1298f4bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3.3\n",
    "test_prompts = [\n",
    "    \"What is eda?\",\n",
    "    \"What is arima?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e36aa",
   "metadata": {},
   "source": [
    "\" EDA stands for Exploratory Data Analysis. It is a crucial step in the data science process, where data scientists and analysts explore and analyze data to discover patterns, relationships, and insights. The goal of EDA is to understand the data's underlying structure, identify outliers or anomalies, and formulate hypotheses for further investigation.\n",
    "In the given context, the speaker is discussing the importance of data management in the field of data science, particularly in the context of the abundance of data generated by generative AI. EDA would be an essential part of this process, as it helps the students in CS 639: Data Management for Data Science to understand and make sense of the vast amounts of data they will encounter.\n",
    "During EDA, various techniques and tools are employed, such as:\n",
    "Summarizing data using descriptive statistics (mean, median, mode, standard deviation, etc.)\n",
    "Visualizing data through charts, graphs, and plots (histograms, scatter plots, box plots, etc.)\n",
    "Identifying correlations and relationships between variables\n",
    "Detecting outliers and anomalies\n",
    "Formulating hypotheses and questions for further analysis\n",
    "By engaging in EDA, students in this course will develop a strong foundation in data analysis and management, enabling them to effectively handle and interpret the massive amounts of data generated in today's data-driven world.\",\n",
    "\"Arima, short for AutoRegressive Integrated Moving Average, is a statistical modeling technique used in time series analysis and forecasting. It is not directly mentioned in the provided context, but I can explain it for you.\n",
    "\n",
    "The Arima model consists of three components:\n",
    "\n",
    "AutoRegressive (AR): This part of the model captures the relationship between an observation and a specified number of lagged observations. It helps to understand how past values influence the current value.\n",
    "\n",
    "Integrated (I): This component involves differencing the data to make it stationary, meaning that the mean, variance, and autocorrelation structure do not change over time. This step is crucial for handling non-stationary data, which is common in many real-world time series.\n",
    "\n",
    "Moving Average (MA): This component models the relationship between an observation and a residual error from a moving average model applied to lagged observations. It helps to capture the impact of random shocks or noise on the time series.\n",
    "\n",
    "The combination of these three components allows the Arima model to capture complex patterns and relationships in time series data, making it a powerful tool for forecasting and understanding the underlying dynamics of the data.\n",
    "\n",
    "In the context of data management for data science, understanding and applying techniques like Arima can help data scientists and analysts make more accurate predictions and gain deeper insights from the vast amounts of data generated by various sources, including generative AI.\",\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bae66a1-6f6f-42f3-b045-6e4529885d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall, the RAG pipeline gave more accurate and grounded answers, especially for fact-based questions. The fine-tuned model hallucinated course content.\n",
    "# However, the fine-tuned model was slightly more fluent in writing style."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
